{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "039e9ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import deps \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import Lasso\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# ... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae3a8e2",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "What makes the perfect bottle of wine? \n",
    "\n",
    "Wine is a major industry, with sales projected to steadily grow beyond $40 billion USD by 2029. [Source](https://www.statista.com/statistics/922403/global-wine-market-size/)\n",
    "\n",
    "For the longest time, the secrets of the timeless art of winemaking were restricted to the intuitions and implicit knowledge of the vintners themselves. Today it is possible to apply the techniques of machine learning to analyze the chemical components of wine to determine how they influence the quality rating of the wine.\n",
    "\n",
    "This study conducts machine learning analysis on the chemical constitutents of 6497 different wines (1599 reds and 4898 white ) to identify the predictive relationships between these features and wine quality. \n",
    "\n",
    "The purpose of this study is to show how machine learning can be applied to commercial pursuits and potentially improve sales and production quality of products. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "f49480d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data \n",
    "#Drop wine type from the get-go. May change later\n",
    "all_wine_raw_df = pd.read_csv('./Wine_data_both.csv').drop(columns=['Wine'])\n",
    "red_wine_df = pd.read_csv('./Wine_data_red.csv')\n",
    "white_wine_df = pd.read_csv('./Wine_data_white.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "ebd49a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5991 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         5991 non-null   float64\n",
      " 1   volatile acidity      5991 non-null   float64\n",
      " 2   citric acid           5991 non-null   float64\n",
      " 3   residual sugar        5991 non-null   float64\n",
      " 4   chlorides             5991 non-null   float64\n",
      " 5   free sulfur dioxide   5991 non-null   float64\n",
      " 6   total sulfur dioxide  5991 non-null   float64\n",
      " 7   density               5991 non-null   float64\n",
      " 8   pH                    5991 non-null   float64\n",
      " 9   sulphates             5991 non-null   float64\n",
      " 10  alcohol               5991 non-null   float64\n",
      " 11  quality               5991 non-null   int64  \n",
      " 12  Outlier               5991 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 655.3 KB\n",
      "All wine data types None\n",
      "all wine value counts quality\n",
      "6    2691\n",
      "5    1994\n",
      "7     995\n",
      "4     179\n",
      "9     132\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5991 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36            20.7      0.045   \n",
       "1               6.3             0.300         0.34             1.6      0.049   \n",
       "2               8.1             0.280         0.40             6.9      0.050   \n",
       "3               7.2             0.230         0.32             8.5      0.058   \n",
       "4               7.2             0.230         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "6492            6.2             0.600         0.08             2.0      0.090   \n",
       "6493            5.9             0.550         0.10             2.2      0.062   \n",
       "6494            6.3             0.510         0.13             2.3      0.076   \n",
       "6495            5.9             0.645         0.12             2.0      0.075   \n",
       "6496            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "6492                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "6493                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "6494                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "6495                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "6496                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  Outlier  \n",
       "0         8.8        6        1  \n",
       "1         9.5        6        1  \n",
       "2        10.1        6        1  \n",
       "3         9.9        6        1  \n",
       "4         9.9        6        1  \n",
       "...       ...      ...      ...  \n",
       "6492     10.5        5        1  \n",
       "6493     11.2        6        1  \n",
       "6494     11.0        6        1  \n",
       "6495     10.2        5        1  \n",
       "6496     11.0        6        1  \n",
       "\n",
       "[5991 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inspect raw data \n",
    "print('All wine data types', all_wine_raw_df.info())\n",
    "print('all wine value counts', all_wine_raw_df['quality'].value_counts())\n",
    "# Try separating red and white or wine types \n",
    "display(all_wine_raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63534037",
   "metadata": {},
   "source": [
    "### Data Preparation, Encoding & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae503a3",
   "metadata": {},
   "source": [
    "One of the biggest challenges we faced was an significantly imbalanced data set. The minority classes, with quality =(3, 4, 9) were underepresented by several orders of magnitude compared to the majority class with quality=9 just having 5 samples and quality=6, the most frequent approx 3,000. \n",
    "\n",
    "Initial experiments were unable to come up with a model with sufficient sensitivity to predict minority classes with this sort of discrepancy. So we had to get clever. \n",
    "\n",
    "The cell below takes the mean values of the minority classes and uses it as the \"typical value\" for that class. Since 9 is so under-represented, it likely wouldn't be realistic to generalize from its average with only n=5 data points using SMOTE. So the decision was made to merge quality=8 into it. And do do the same for 3s and 4's. We argue this loss in target resolution is made up for improved model performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77279b7b",
   "metadata": {},
   "source": [
    "Since our EDA discovered that our data had several outliers, we chose to remove these from the dataset. \n",
    "We decided to use the IsolationForest ML model to detect outliers rather than zscore or IQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "280bec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.01, n_estimators=400,  random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "iso_forest.fit(all_wine_raw_df)\n",
    "\n",
    "# Predict anomalies\n",
    "outliers = iso_forest.predict(all_wine_raw_df)\n",
    "# -1 for outliers, 1 for inliers\n",
    "\n",
    "all_wine_raw_df['Outlier'] = outliers\n",
    "\n",
    "# Filter out outliers\n",
    "\n",
    "all_wine_raw_df = all_wine_raw_df[all_wine_raw_df['Outlier'] == 1].drop(columns=['Outlier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "3cc328de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values for highest rated wines (quality == 9):\n",
      "fixed acidity             6.921429\n",
      "volatile acidity          0.256286\n",
      "citric acid               0.328714\n",
      "residual sugar            4.379286\n",
      "chlorides                 0.038443\n",
      "free sulfur dioxide      33.157143\n",
      "total sulfur dioxide    118.742857\n",
      "density                   0.992217\n",
      "pH                        3.239429\n",
      "sulphates                 0.494857\n",
      "alcohol                  11.452857\n",
      "quality                   9.000000\n",
      "dtype: float64\n",
      "\n",
      "Mean values for lowest rated wines (quality == 3):\n",
      "fixed acidity             7.119565\n",
      "volatile acidity          0.311467\n",
      "citric acid               0.306848\n",
      "residual sugar            4.573370\n",
      "chlorides                 0.048261\n",
      "free sulfur dioxide      22.038043\n",
      "total sulfur dioxide    130.565217\n",
      "density                   0.994436\n",
      "pH                        3.193043\n",
      "sulphates                 0.485978\n",
      "alcohol                  10.078804\n",
      "quality                   4.000000\n",
      "dtype: float64\n",
      "\n",
      "Mean values for average rated wines (quality == 6):\n",
      "fixed acidity             6.898261\n",
      "volatile acidity          0.278878\n",
      "citric acid               0.321352\n",
      "residual sugar            5.713565\n",
      "chlorides                 0.046796\n",
      "free sulfur dioxide      33.351304\n",
      "total sulfur dioxide    126.367391\n",
      "density                   0.994010\n",
      "pH                        3.208435\n",
      "sulphates                 0.502261\n",
      "alcohol                  10.598848\n",
      "quality                   6.000000\n",
      "dtype: float64\n",
      "\n",
      "Difference in mean values between highest and lowest:\n",
      "fixed acidity           -0.198137\n",
      "volatile acidity        -0.055182\n",
      "citric acid              0.021866\n",
      "residual sugar          -0.194084\n",
      "chlorides               -0.009818\n",
      "free sulfur dioxide     11.119099\n",
      "total sulfur dioxide   -11.822360\n",
      "density                 -0.002219\n",
      "pH                       0.046385\n",
      "sulphates                0.008879\n",
      "alcohol                  1.374053\n",
      "quality                  5.000000\n",
      "dtype: float64\n",
      "\n",
      "Difference in mean values between highest and average:\n",
      "fixed acidity           0.023168\n",
      "volatile acidity       -0.022593\n",
      "citric acid             0.007362\n",
      "residual sugar         -1.334280\n",
      "chlorides              -0.008353\n",
      "free sulfur dioxide    -0.194161\n",
      "total sulfur dioxide   -7.624534\n",
      "density                -0.001794\n",
      "pH                      0.030994\n",
      "sulphates              -0.007404\n",
      "alcohol                 0.854009\n",
      "quality                 3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Upgrade all 8s to become 9s and 3s to become 4s (binning)\n",
    "all_wine_raw_df.loc[all_wine_raw_df['quality'] == 8, 'quality'] = 9\n",
    "all_wine_raw_df.loc[all_wine_raw_df['quality'] == 3, 'quality'] = 4\n",
    "\n",
    "all_9s = all_wine_raw_df[all_wine_raw_df['quality'] == 9]\n",
    "all_4s = all_wine_raw_df[all_wine_raw_df['quality'] == 4]\n",
    "all_6s = all_wine_raw_df[all_wine_raw_df['quality'] == 6]\n",
    "\n",
    "\n",
    "mean_all_9s = all_9s.mean()\n",
    "mean_all_4s = all_4s.mean()\n",
    "mean_all_6s = all_6s.mean()\n",
    "# Compare the means (difference between highest and lowest rated wines)\n",
    "mean_difference_high_to_low = mean_all_9s - mean_all_4s\n",
    "mean_difference_high_to_average = mean_all_9s - mean_all_6s\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean values for highest rated wines (quality == 9):\")\n",
    "print(mean_all_9s)\n",
    "print(\"\\nMean values for lowest rated wines (quality == 3):\")\n",
    "print(mean_all_4s)\n",
    "print(\"\\nMean values for average rated wines (quality == 6):\")\n",
    "print(mean_all_6s)\n",
    "print(\"\\nDifference in mean values between highest and lowest:\")\n",
    "print(mean_difference_high_to_low)\n",
    "print(\"\\nDifference in mean values between highest and average:\")\n",
    "print(mean_difference_high_to_average)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ace66",
   "metadata": {},
   "source": [
    "We then use the **generate_synthetic_samples** function to inject a number of statistically similar values into the sample set. \n",
    "\n",
    "It achieves this by using a multivariate normal distribution, which describes a set of random variables that may be correlated with each other, where each variable follows a normal distribution. \n",
    "\n",
    "In order realistially simulate the possibility of covariance between the different values of a single data entry, we pass the covariance matrix of the dataframe into np.random.multivariate_normal. It then multiplies this by a noise scale, ensuring that there the results resemble the average in the dataset without overly imitating it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "5067c7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "1               6.3              0.30         0.34             1.6      0.049   \n",
      "2               8.1              0.28         0.40             6.9      0.050   \n",
      "3               7.2              0.23         0.32             8.5      0.058   \n",
      "4               7.2              0.23         0.32             8.5      0.058   \n",
      "5               8.1              0.28         0.40             6.9      0.050   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "6484            7.5              0.31         0.41             2.4      0.065   \n",
      "6486            7.2              0.66         0.33             2.5      0.068   \n",
      "6490            6.3              0.51         0.13             2.3      0.076   \n",
      "6494            6.3              0.51         0.13             2.3      0.076   \n",
      "6496            6.0              0.31         0.47             3.6      0.067   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
      "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
      "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
      "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
      "5                    30.0                  97.0  0.99510  3.26       0.44   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "6484                 34.0                  60.0  0.99492  3.34       0.85   \n",
      "6486                 34.0                 102.0  0.99414  3.27       0.78   \n",
      "6490                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "6494                 29.0                  40.0  0.99574  3.42       0.75   \n",
      "6496                 18.0                  42.0  0.99549  3.39       0.66   \n",
      "\n",
      "      alcohol  quality  \n",
      "1         9.5        6  \n",
      "2        10.1        6  \n",
      "3         9.9        6  \n",
      "4         9.9        6  \n",
      "5        10.1        6  \n",
      "...       ...      ...  \n",
      "6484     11.4        6  \n",
      "6486     12.8        6  \n",
      "6490     11.0        6  \n",
      "6494     11.0        6  \n",
      "6496     11.0        6  \n",
      "\n",
      "[2300 rows x 12 columns] 6s\n",
      "    fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0        6.933517          0.245021     0.323587        4.410820   0.036613   \n",
      "1        6.798622          0.265060     0.354854        5.235066   0.039571   \n",
      "2        7.134988          0.290440     0.319817        3.262237   0.036579   \n",
      "3        7.115491          0.283046     0.314870        4.250277   0.038730   \n",
      "4        6.781285          0.279250     0.332263        4.528177   0.040536   \n",
      "5        7.109804          0.282248     0.322213        2.871592   0.040082   \n",
      "6        6.985330          0.272832     0.344435        5.210648   0.039632   \n",
      "7        6.832265          0.205785     0.318889        4.322863   0.034608   \n",
      "8        6.956942          0.245565     0.321225        5.275463   0.038943   \n",
      "9        6.822041          0.275079     0.333783        4.340659   0.038850   \n",
      "10       7.003800          0.283937     0.306910        3.966855   0.042512   \n",
      "11       7.011001          0.253131     0.344015        4.389243   0.037710   \n",
      "12       6.953678          0.243830     0.297616        3.965240   0.037703   \n",
      "13       7.050462          0.228668     0.321382        4.080024   0.036271   \n",
      "14       6.833212          0.263548     0.333837        3.302911   0.038034   \n",
      "15       6.593001          0.258950     0.318365        3.706509   0.034837   \n",
      "16       6.842196          0.230741     0.367158        3.378421   0.035499   \n",
      "17       6.790633          0.264641     0.371109        5.330171   0.035217   \n",
      "18       6.806202          0.267846     0.323113        5.613164   0.039037   \n",
      "19       6.847980          0.253943     0.322594        4.893807   0.036082   \n",
      "20       6.924976          0.259831     0.348536        5.428610   0.044004   \n",
      "21       6.965622          0.227135     0.363036        4.842941   0.038717   \n",
      "22       6.933831          0.230640     0.324163        4.797229   0.041613   \n",
      "23       7.038361          0.257744     0.314365        4.252478   0.041431   \n",
      "24       6.744343          0.244600     0.359725        4.776609   0.036776   \n",
      "25       6.986117          0.278906     0.365910        5.381919   0.037572   \n",
      "26       6.795079          0.232072     0.322607        3.381224   0.035475   \n",
      "27       7.012879          0.224279     0.325564        3.458726   0.039912   \n",
      "28       7.006018          0.274179     0.342932        5.486546   0.041786   \n",
      "29       6.955751          0.270819     0.323899        4.199651   0.039928   \n",
      "30       7.146855          0.254582     0.314011        3.345781   0.040719   \n",
      "31       6.930864          0.244935     0.340886        4.866754   0.037830   \n",
      "32       6.655103          0.288143     0.335806        3.656320   0.041005   \n",
      "33       6.843416          0.227874     0.319937        2.627503   0.033810   \n",
      "34       7.178880          0.274840     0.358800        4.429185   0.040627   \n",
      "35       6.849283          0.253254     0.338655        3.834079   0.035223   \n",
      "36       6.854656          0.231243     0.332896        4.918006   0.033232   \n",
      "37       7.011525          0.240855     0.323784        4.239204   0.032876   \n",
      "38       7.045881          0.229764     0.344126        4.260604   0.036720   \n",
      "39       6.974600          0.280215     0.325467        5.232273   0.039450   \n",
      "\n",
      "    free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
      "0             30.379059            120.300206  0.991958  3.224617   0.499404   \n",
      "1             33.550802            122.991144  0.992774  3.234733   0.473263   \n",
      "2             32.782149            121.186788  0.992095  3.239366   0.517759   \n",
      "3             27.742354            101.158872  0.992092  3.193215   0.517097   \n",
      "4             34.148987            114.405809  0.992035  3.268064   0.516663   \n",
      "5             32.481138            116.792499  0.991825  3.233788   0.505540   \n",
      "6             33.914592            120.680012  0.993076  3.275948   0.501636   \n",
      "7             31.682438            119.585012  0.991774  3.243818   0.475236   \n",
      "8             32.527911            125.868311  0.992955  3.235921   0.492113   \n",
      "9             32.073956            119.225419  0.992025  3.265815   0.511954   \n",
      "10            34.000358            111.388135  0.992494  3.290268   0.529736   \n",
      "11            37.555894            130.153414  0.992106  3.241519   0.483212   \n",
      "12            34.812610            116.985623  0.991735  3.270946   0.490715   \n",
      "13            36.223509            124.831236  0.991824  3.210691   0.478005   \n",
      "14            28.432802            103.513414  0.991984  3.283759   0.529723   \n",
      "15            34.934551            126.473302  0.991387  3.293788   0.482997   \n",
      "16            30.094351            109.849934  0.991719  3.276474   0.504289   \n",
      "17            34.441468            121.047281  0.991682  3.225417   0.487627   \n",
      "18            35.515418            119.966675  0.992832  3.223612   0.496881   \n",
      "19            35.139200            127.760585  0.992093  3.235923   0.492822   \n",
      "20            35.250094            120.520672  0.993533  3.263796   0.501650   \n",
      "21            36.453321            128.271034  0.992638  3.283750   0.491119   \n",
      "22            36.776072            125.010596  0.992551  3.220757   0.495419   \n",
      "23            35.500809            113.007388  0.992096  3.224021   0.443736   \n",
      "24            32.308669            117.585064  0.991624  3.205547   0.475237   \n",
      "25            34.929295            118.275398  0.992982  3.263925   0.486403   \n",
      "26            36.685598            127.924308  0.991849  3.227554   0.509844   \n",
      "27            31.485366            113.326909  0.992191  3.262433   0.482066   \n",
      "28            32.943532            112.094054  0.992966  3.216093   0.481714   \n",
      "29            33.111624            124.658171  0.992321  3.253839   0.481142   \n",
      "30            28.411300            116.845175  0.992281  3.212263   0.503621   \n",
      "31            31.302628            103.183483  0.992407  3.242780   0.496569   \n",
      "32            30.575314            110.930545  0.991540  3.253672   0.493327   \n",
      "33            31.540724            120.602198  0.991306  3.260939   0.519592   \n",
      "34            31.687935            122.024469  0.992641  3.228256   0.521785   \n",
      "35            31.565587            117.794064  0.991940  3.257622   0.490400   \n",
      "36            34.273471            125.616531  0.992348  3.243190   0.506289   \n",
      "37            33.138984            121.032729  0.991848  3.224273   0.486351   \n",
      "38            33.179846            107.065421  0.991880  3.223859   0.492852   \n",
      "39            32.592617            121.620483  0.992607  3.233026   0.477606   \n",
      "\n",
      "      alcohol   quality  \n",
      "0   11.446816  9.063939  \n",
      "1   11.308570  8.970317  \n",
      "2   11.546174  8.965682  \n",
      "3   11.605121  9.342154  \n",
      "4   11.572084  8.960552  \n",
      "5   11.455375  8.898568  \n",
      "6   11.264348  8.995497  \n",
      "7   11.510903  9.079216  \n",
      "8   11.203704  8.928347  \n",
      "9   11.464976  9.037897  \n",
      "10  11.629148  9.076357  \n",
      "11  11.660354  9.291206  \n",
      "12  11.770586  9.025180  \n",
      "13  11.615649  9.137232  \n",
      "14  11.672694  8.831575  \n",
      "15  11.773536  9.211848  \n",
      "16  11.591879  8.999423  \n",
      "17  11.805244  9.073517  \n",
      "18  11.163908  9.000687  \n",
      "19  11.552557  9.150861  \n",
      "20  10.926853  8.754247  \n",
      "21  11.360331  9.003570  \n",
      "22  11.248667  8.912018  \n",
      "23  11.380617  8.980330  \n",
      "24  11.739858  9.024164  \n",
      "25  11.195329  9.028998  \n",
      "26  11.356090  8.918515  \n",
      "27  11.358103  8.868599  \n",
      "28  11.328604  8.856165  \n",
      "29  11.298063  9.045801  \n",
      "30  11.321616  8.725993  \n",
      "31  11.544791  9.073928  \n",
      "32  11.658217  9.122612  \n",
      "33  11.750522  8.978143  \n",
      "34  11.372378  9.024014  \n",
      "35  11.560160  8.845313  \n",
      "36  11.280590  9.090911  \n",
      "37  11.578237  9.202069  \n",
      "38  11.669117  9.078684  \n",
      "39  11.427203  8.817963   synth\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_samples(mean_values, n_samples, noise_scale=0.03):\n",
    "    synthetic_samples = np.random.multivariate_normal(\n",
    "        mean=mean_values, \n",
    "        cov=all_wine_raw_df.cov() * noise_scale, \n",
    "        size=n_samples\n",
    "    )\n",
    "    return pd.DataFrame(synthetic_samples, columns=mean_values.index)\n",
    "# Grab all the minority classes in the data and take their means, inject the magic # 30 \n",
    "synthetic_9s = generate_synthetic_samples(mean_all_9s, 40)\n",
    "print(all_6s, '6s')\n",
    "print(synthetic_9s, 'synth')\n",
    "\n",
    "synthetic_4s = generate_synthetic_samples(mean_all_4s, 40)\n",
    "# Add the target column to the synthetic samples\n",
    "synthetic_9s['quality'] = 9\n",
    "synthetic_4s['quality'] = 4\n",
    "# Combine synthetic samples with the original data\n",
    "synthetic_data = pd.concat([synthetic_9s, synthetic_4s])\n",
    "combined_data = pd.concat([all_wine_raw_df, synthetic_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca9242",
   "metadata": {},
   "source": [
    "Below we repeat the steps performed a few cells above to verify that the values of the updated data still resemble what they were originally.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "475ea713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean values for highest rated wines (quality == 9):\n",
      "fixed acidity             6.803953\n",
      "volatile acidity          0.289154\n",
      "citric acid               0.329674\n",
      "residual sugar            5.349519\n",
      "chlorides                 0.040206\n",
      "free sulfur dioxide      34.722753\n",
      "total sulfur dioxide    118.009082\n",
      "density                   0.992414\n",
      "pH                        3.227434\n",
      "sulphates                 0.508304\n",
      "alcohol                  11.696864\n",
      "quality                   9.000000\n",
      "dtype: float64\n",
      "\n",
      "Mean values for lowest rated wines (quality == 3):\n",
      "\n",
      "Mean values for average rated wines (quality == 6):\n",
      "fixed acidity             7.166490\n",
      "volatile acidity          0.312641\n",
      "citric acid               0.322774\n",
      "residual sugar            5.532023\n",
      "chlorides                 0.053393\n",
      "free sulfur dioxide      31.218562\n",
      "total sulfur dioxide    115.623450\n",
      "density                   0.994528\n",
      "pH                        3.218278\n",
      "sulphates                 0.530269\n",
      "alcohol                  10.589054\n",
      "quality                   6.000000\n",
      "dtype: float64\n",
      "\n",
      "Difference in mean values between highest and lowest:\n",
      "fixed acidity           -0.534437\n",
      "volatile acidity        -0.154687\n",
      "citric acid              0.055978\n",
      "residual sugar           1.192415\n",
      "chlorides               -0.015787\n",
      "free sulfur dioxide     12.600350\n",
      "total sulfur dioxide    12.930632\n",
      "density                 -0.002406\n",
      "pH                      -0.008469\n",
      "sulphates                0.010561\n",
      "alcohol                  1.513384\n",
      "quality                  5.000000\n",
      "dtype: float64\n",
      "\n",
      "Difference in mean values between highest and average:\n",
      "fixed acidity          -0.368530\n",
      "volatile acidity       -0.023228\n",
      "citric acid             0.007430\n",
      "residual sugar         -0.164166\n",
      "chlorides              -0.013005\n",
      "free sulfur dioxide     3.577357\n",
      "total sulfur dioxide    2.810223\n",
      "density                -0.002105\n",
      "pH                      0.008864\n",
      "sulphates              -0.021443\n",
      "alcohol                 1.103293\n",
      "quality                 3.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "all_9s = combined_data[combined_data['quality'] == 9]\n",
    "all_4s = combined_data[combined_data['quality'] == 4]\n",
    "all_6s = combined_data[combined_data['quality'] == 6]\n",
    "\n",
    "\n",
    "synth_mean_all_9s = all_9s.mean()\n",
    "synth_mean_all_4s = all_4s.mean()\n",
    "# Compare the means (difference between highest and lowest rated wines)\n",
    "synth_mean_difference_high_to_low = synth_mean_all_9s - synth_mean_all_4s\n",
    "synth_mean_difference_high_to_average = mean_all_9s - mean_all_6s\n",
    "\n",
    "# Display the results\n",
    "print(\"Mean values for highest rated wines (quality == 9):\")\n",
    "print(synth_mean_all_9s)\n",
    "print(\"\\nMean values for lowest rated wines (quality == 3):\")\n",
    "print(\"\\nMean values for average rated wines (quality == 6):\")\n",
    "print(mean_all_6s)\n",
    "print(\"\\nDifference in mean values between highest and lowest:\")\n",
    "print(synth_mean_difference_high_to_low)\n",
    "print(\"\\nDifference in mean values between highest and average:\")\n",
    "print(synth_mean_difference_high_to_average)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa980c7",
   "metadata": {},
   "source": [
    "Later, we apply cross validation techniques to verify the integrity of this synthetic data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "16e35ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encode the wine type, 0 is White, Red is 1\n",
    "# Gretel.ai ---> Generating synthetic data \n",
    "\n",
    "# We dropped wine type for the time being\n",
    "#combined_data['wine type'] = all_wine_raw_df['Wine'].map({'White': 0, 'Red': 1})\n",
    "\n",
    "# Define the feature and target variables\n",
    "# Note: We learned what features to drop through EDA and in the optimizations performed below. \n",
    "X = combined_data.drop(columns=['quality', 'citric acid', 'chlorides', 'density' ], axis=1)\n",
    "y =  combined_data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "346d06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with Outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.75      0.23      0.35        52\n",
      "           5       0.69      0.70      0.69       423\n",
      "           6       0.64      0.77      0.70       565\n",
      "           7       0.69      0.49      0.57       214\n",
      "           9       0.81      0.38      0.52        45\n",
      "\n",
      "    accuracy                           0.67      1299\n",
      "   macro avg       0.72      0.51      0.57      1299\n",
      "weighted avg       0.67      0.67      0.66      1299\n",
      "\n",
      "[[ 12  27  13   0   0]\n",
      " [  4 296 121   2   0]\n",
      " [  0 104 434  27   0]\n",
      " [  0   5 100 105   4]\n",
      " [  0   0  10  18  17]]\n",
      "Model without Outliers\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.93      0.26      0.41        53\n",
      "           5       0.73      0.71      0.72       417\n",
      "           6       0.62      0.80      0.70       550\n",
      "           7       0.77      0.50      0.61       235\n",
      "           9       0.88      0.34      0.49        44\n",
      "\n",
      "    accuracy                           0.68      1299\n",
      "   macro avg       0.79      0.52      0.59      1299\n",
      "weighted avg       0.71      0.68      0.67      1299\n",
      "\n",
      "[[ 14  26  13   0   0]\n",
      " [  1 297 119   0   0]\n",
      " [  0  82 441  27   0]\n",
      " [  0   2 113 118   2]\n",
      " [  0   0  20   9  15]]\n",
      "Cross-validation scores with outliers: 0.6653242242336914\n",
      "Cross-validation scores without outliers: 0.6697491474127524\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a20785c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Determine if data is balanced or imbalanced\n",
    "plt.figure(figsize=(10, 6))\n",
    "y.value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "plt.xlabel('Quality')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.show()\n",
    "\n",
    "# Clustering or feature engineering by clumping 3s/4s/5s/ low  6s/ medium/ 7,8,9 high quality "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6a323",
   "metadata": {},
   "source": [
    "Since our data is still very imbalanced, we want apply a few techniques to compensate for it. One method is to calculate class weights, which will help inform the model to learn more from the minority classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "702debc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {4: 4.969377990430622, 5: 0.6152843601895734, 6: 0.4599645704162976, 7: 1.211901983663944, 9: 5.738121546961326}\n"
     ]
    }
   ],
   "source": [
    "# Since our data is very imbalanced, lets try calculating class weights \n",
    "unique_classes = np.array([4, 5, 6, 7, 9])\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(unique_classes, class_weights)}\n",
    "\n",
    "print(f'Class weights: {class_weight_dict}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825693e",
   "metadata": {},
   "source": [
    "Next we wanted to look into feature selection. We learned that the most significant features are 'residual sugar', 'free sulfur dioxide', 'total sulfur dioxide', and 'alcohol'. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e29dc1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.7321545332974203\n",
      "Selected Features: Index(['residual sugar', 'free sulfur dioxide', 'total sulfur dioxide',\n",
      "       'alcohol'],\n",
      "      dtype='object')\n",
      "Elastic Net Mean Squared Error: 0.9343007077842189\n",
      "Elastic Net Coefficients: [-0.         -0.         -0.          0.00759258 -0.00210842  0.\n",
      "  0.          0.        ]\n",
      "                feature         VIF\n",
      "0         fixed acidity   32.588047\n",
      "1      volatile acidity    7.197255\n",
      "2        residual sugar    3.320121\n",
      "3   free sulfur dioxide    8.647710\n",
      "4  total sulfur dioxide   13.127633\n",
      "5                    pH  143.536215\n",
      "6             sulphates   18.285189\n",
      "7               alcohol   80.789337\n",
      "                      fixed acidity  volatile acidity  residual sugar  \\\n",
      "fixed acidity              1.000000          0.211711       -0.120144   \n",
      "volatile acidity           0.211711          1.000000       -0.209303   \n",
      "residual sugar            -0.120144         -0.209303        1.000000   \n",
      "free sulfur dioxide       -0.282931         -0.354098        0.410553   \n",
      "total sulfur dioxide      -0.326447         -0.415789        0.498920   \n",
      "pH                        -0.239422          0.273270       -0.276015   \n",
      "sulphates                  0.286942          0.211298       -0.192135   \n",
      "alcohol                   -0.103567         -0.041060       -0.367573   \n",
      "\n",
      "                      free sulfur dioxide  total sulfur dioxide        pH  \\\n",
      "fixed acidity                   -0.282931             -0.326447 -0.239422   \n",
      "volatile acidity                -0.354098             -0.415789  0.273270   \n",
      "residual sugar                   0.410553              0.498920 -0.276015   \n",
      "free sulfur dioxide              1.000000              0.721516 -0.154485   \n",
      "total sulfur dioxide             0.721516              1.000000 -0.246064   \n",
      "pH                              -0.154485             -0.246064  1.000000   \n",
      "sulphates                       -0.182773             -0.272387  0.233959   \n",
      "alcohol                         -0.180804             -0.268817  0.117360   \n",
      "\n",
      "                      sulphates   alcohol  \n",
      "fixed acidity          0.286942 -0.103567  \n",
      "volatile acidity       0.211298 -0.041060  \n",
      "residual sugar        -0.192135 -0.367573  \n",
      "free sulfur dioxide   -0.182773 -0.180804  \n",
      "total sulfur dioxide  -0.272387 -0.268817  \n",
      "pH                     0.233959  0.117360  \n",
      "sulphates              1.000000  0.009975  \n",
      "alcohol                0.009975  1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Feature Selection and regularization : What features can we drop? \n",
    "# Here we learned that density and pH could be dropped\n",
    "# Initialize Lasso regression\n",
    "lasso = Lasso(alpha=0.1)  \n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred_lasso)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Check selected features\n",
    "selected_features = X_train.columns[lasso.coef_ != 0]\n",
    "print(f'Selected Features: {selected_features}')\n",
    "\n",
    "\n",
    "# Calculate variance inflation factor for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "print(vif_data)\n",
    "\n",
    "# Based on these results, we could consider dropping at least pH and density, and possibly also alcohol \n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Display the correlation matrix\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "0bd29af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Don't end up using, will likely drop\n",
    "adasyn = ADASYN(random_state=42, n_neighbors=3)\n",
    "X_resampled, y_resampled = adasyn.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e270c761",
   "metadata": {},
   "source": [
    "### Scaling the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "4b3a0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, scaling data seems to throw everything out here, probably because nothing in the data is measured in universal units.\n",
    "# Will likey drop\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform the training data\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_resampled)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "# Transform the testing data (use the same scaler fitted on the training data)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf0786",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef11d38",
   "metadata": {},
   "source": [
    "For our model we decided to use the versatile RandomizedTreeClassifier algorithm, which, after some experimentation with other algos proved to consistently give the best results.  \n",
    "\n",
    "First, we did some hyperparameter tuning to try to find the best model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "29ac2d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simpler parameter grid for RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c98c5e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=400; total time=   2.4s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=400; total time=   2.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=400; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.9s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=500; total time=   2.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=500; total time=   2.7s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   2.2s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=300; total time=   1.5s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.1s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=300; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=500; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=500; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   2.0s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   2.1s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   2.2s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=400; total time=   1.6s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   1.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   1.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=10, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END criterion=log_loss, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.1s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   2.9s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=   3.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   1.0s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=20, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   1.3s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.7s\n",
      "[CV] END criterion=gini, max_depth=10, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.0s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.8s\n",
      "[CV] END criterion=entropy, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=500; total time=   2.1s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.9s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.5s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=500; total time=   3.4s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=gini, max_depth=30, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=200; total time=   0.8s\n",
      "[CV] END criterion=gini, max_depth=20, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   2.0s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=   2.3s\n",
      "[CV] END criterion=entropy, max_depth=30, max_features=log2, min_samples_leaf=3, min_samples_split=5, n_estimators=100; total time=   0.6s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=100; total time=   0.4s\n",
      "[CV] END criterion=log_loss, max_depth=20, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.2s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "[CV] END criterion=log_loss, max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time=   1.1s\n",
      "Best RFC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.83      0.19      0.31        52\n",
      "           5       0.70      0.71      0.71       423\n",
      "           6       0.64      0.79      0.71       565\n",
      "           7       0.75      0.50      0.60       214\n",
      "           9       0.95      0.42      0.58        45\n",
      "\n",
      "    accuracy                           0.68      1299\n",
      "   macro avg       0.78      0.52      0.58      1299\n",
      "weighted avg       0.70      0.68      0.67      1299\n",
      "\n",
      "Best RFC Confusion Matrix:\n",
      "[[ 10  26  16   0   0]\n",
      " [  2 302 118   1   0]\n",
      " [  0  98 445  22   0]\n",
      " [  0   6  99 108   1]\n",
      " [  0   0  13  13  19]]\n"
     ]
    }
   ],
   "source": [
    "# Define the actual model code using what we've learned and search for a best model \n",
    "\n",
    "# Initialize RFC\n",
    "rfc = RandomForestClassifier(random_state=42, class_weight=class_weight_dict)\n",
    "# Initialize the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rfc,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=50,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1 \n",
    ")\n",
    "\n",
    "# Perform the random search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_rfc = random_search.best_estimator_\n",
    "\n",
    "# Predict on the scaled test data\n",
    "y_pred_rfc = best_rfc.predict(X_test)\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Best RFC Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rfc))\n",
    "print(\"Best RFC Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "402a9db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(class_weight={4: 4.969377990430622,\n",
      "                                     5: 0.6152843601895734,\n",
      "                                     6: 0.4599645704162976,\n",
      "                                     7: 1.211901983663944,\n",
      "                                     9: 5.738121546961326},\n",
      "                       criterion='log_loss', max_depth=30, n_estimators=500,\n",
      "                       random_state=42)\n",
      "Best RFC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           4       0.92      0.46      0.62        26\n",
      "           5       0.79      0.70      0.74       308\n",
      "           6       0.70      0.88      0.78       460\n",
      "           7       0.80      0.53      0.64       165\n",
      "           9       1.00      0.41      0.58        22\n",
      "\n",
      "    accuracy                           0.74       981\n",
      "   macro avg       0.84      0.60      0.67       981\n",
      "weighted avg       0.76      0.74      0.73       981\n",
      "\n",
      "Best RFC Confusion Matrix:\n",
      "[[ 12   6   8   0   0]\n",
      " [  1 216  86   5   0]\n",
      " [  0  46 403  11   0]\n",
      " [  0   4  74  87   0]\n",
      " [  0   0   7   6   9]]\n"
     ]
    }
   ],
   "source": [
    "print(best_rfc)\n",
    "classifier = RandomForestClassifier(class_weight=class_weight_dict, criterion='log_loss', max_depth=30, max_features='log2', n_estimators=500, random_state=42)\n",
    "classifier.fit(X=X_train, y=y_train)\n",
    "y_pred_best = classifier.predict(X_test)\n",
    "\n",
    "print(\"Best RFC Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))\n",
    "print(\"Best RFC Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98894842",
   "metadata": {},
   "source": [
    "### Model Validation and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c102e6e",
   "metadata": {},
   "source": [
    "Our model performs reasonably well for precision, however struggles with recall especially for the minority classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02cbdbb",
   "metadata": {},
   "source": [
    "#### Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467ed2d6",
   "metadata": {},
   "source": [
    "Here we cross-validate the model using StratifiedKFold. We find that our cross validation scores are decent but not great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "32c31e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Score Against Synthetic Data: [0.69960898 0.70210423 0.69809257 0.70946162 0.71684155]\n",
      "Mean Cross-Validation Score Against Synthetic Data: 0.7052217921038615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define cross-validation strategy\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Evaluate the model using cross-validation when trained against synthetic data\n",
    "cv_scores_synthetic_data = cross_val_score(best_rfc, X, y, cv=kfold, scoring='f1_weighted')\n",
    "\n",
    "# Output the cross-validation scores against the da\n",
    "print(f'Cross-Validation Score Against Synthetic Data: {cv_scores_synthetic_data}')\n",
    "print(f'Mean Cross-Validation Score Against Synthetic Data: {np.mean(cv_scores_synthetic_data)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eca1528",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b79518d7",
   "metadata": {},
   "source": [
    "#### A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a705c8",
   "metadata": {},
   "source": [
    "As a control experiment, we run the same model against the raw data. The model is generall less capable across the board, but most notably, is entirely unable to detect the minority classes (quality= 3 and quality=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cce483c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Data RFC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.75      0.14      0.24        43\n",
      "           5       0.70      0.74      0.72       428\n",
      "           6       0.64      0.77      0.70       567\n",
      "           7       0.76      0.51      0.61       216\n",
      "           8       0.86      0.31      0.45        39\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.68      1300\n",
      "   macro avg       0.53      0.35      0.39      1300\n",
      "weighted avg       0.69      0.68      0.67      1300\n",
      "\n",
      "Raw Data Confusion Matrix:\n",
      "[[  0   0   2   4   0   0   0]\n",
      " [  0   6  21  16   0   0   0]\n",
      " [  0   1 317 110   0   0   0]\n",
      " [  0   1 102 437  26   1   0]\n",
      " [  0   0   8  96 111   1   0]\n",
      " [  0   0   0  17  10  12   0]\n",
      " [  0   0   0   1   0   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ai_dev/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ai_dev/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/envs/ai_dev/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('./Wine_data_both.csv') \n",
    "X_raw = raw_data.drop(columns=['quality', 'Wine'])\n",
    "y_raw = raw_data['quality']\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw)\n",
    "raw_classifier = RandomForestClassifier( class_weight=class_weight_dict, criterion='log_loss', max_depth=30, max_features='log2', n_estimators=500, random_state=42)\n",
    "raw_classifier.fit(X=X_train_raw, y=y_train_raw)\n",
    "y_pred_best_raw = raw_classifier.predict(X_test_raw)\n",
    "\n",
    "print(\"Raw Data RFC Classification Report:\")\n",
    "print(classification_report(y_test_raw, y_pred_best_raw))\n",
    "print(\"Raw Data Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_raw, y_pred_best_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b7642c",
   "metadata": {},
   "source": [
    "### Evaluation & Interpretation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "2f0696d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'residual sugar',\n",
      "       'free sulfur dioxide', 'total sulfur dioxide', 'pH', 'sulphates',\n",
      "       'alcohol'],\n",
      "      dtype='object')\n",
      "[0.10332822 0.11599267 0.11440151 0.14860736 0.12395994 0.10626231\n",
      " 0.09129405 0.19615393]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature Importances: \n",
    "print(X_train.columns)\n",
    "print(classifier.feature_importances_)\n",
    "importances = classifier.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importances from Random Forest Model')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505360b3",
   "metadata": {},
   "source": [
    "Alcohol, and sulfur dioxide (free/total) are the three strongest predictors of wine quality. Interestingly, alcohol is the most important feature. This made us wonder if wine raters tended to perfer stronger wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "c0801def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alcohol content of wines rated 4: 10.078804347826088\n",
      "Alcohol content of wines rated 5: 9.849478016024692\n",
      "Alcohol content of wines rated 6: 10.598847826079567\n",
      "Alcohol content of wines rated 7: 11.400586569575243\n",
      "Alcohol content of wines rated 9: 11.452857142857143\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for quality_class in all_wine_raw_df['quality'].sort_values().unique():\n",
    "    mean_alcohol = all_wine_raw_df[all_wine_raw_df['quality'] == quality_class]['alcohol'].mean()\n",
    "    print(f\"Alcohol content of wines rated {quality_class}: {mean_alcohol}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07944fb3",
   "metadata": {},
   "source": [
    "Sure enough the more highly rated the wine the stronger the alcohol content, although this is not a simple linear relationship. \n",
    "\n",
    "We speculate that since wine rating is a subjective affair perhaps the graders are enjoying themselves a little bit more when they drink the stronger wines, hence this biases their judgement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "b5878172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "46         0.721429         -0.193714     0.068714       -0.020714  -0.024557   \n",
      "189        0.421429         -0.023714     0.048714       -4.120714  -0.008557   \n",
      "204        1.121429         -0.023714    -0.021286        2.079286  -0.014557   \n",
      "278        0.121429         -0.063714    -0.011286        3.179286  -0.005557   \n",
      "282        0.121429         -0.183714    -0.041286       -0.720714  -0.008557   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "4483       1.121429         -0.023714     0.148714        3.179286  -0.019557   \n",
      "4508       1.121429         -0.003714     0.028714        1.779286   0.004443   \n",
      "4774      -0.178571          0.016286    -0.011286        3.179286  -0.006557   \n",
      "5601      -0.578571         -0.123714    -0.151286        1.779286  -0.034557   \n",
      "5770      -0.378571         -0.093714     0.088714        2.379286  -0.028557   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "46             -29.842857            -87.257143 -0.001783 -0.030571   \n",
      "189            -20.842857            -91.257143 -0.003983  0.149429   \n",
      "204             -2.842857              4.742857 -0.000183 -0.040571   \n",
      "278             19.157143             51.742857  0.000317  0.189429   \n",
      "282            -12.842857            -82.257143 -0.001583  0.159429   \n",
      "...                   ...                   ...       ...       ...   \n",
      "4483            26.157143             10.742857 -0.000663  0.009429   \n",
      "4508           -41.842857            -10.257143  0.002017  0.039429   \n",
      "4774            27.157143            -13.257143  0.000897  0.079429   \n",
      "5601            11.157143             34.742857 -0.004983 -0.080571   \n",
      "5770             5.157143             70.742857 -0.003543 -0.190571   \n",
      "\n",
      "      sulphates   alcohol  quality  \n",
      "46    -0.025143  1.652857      5.0  \n",
      "189   -0.045143  2.552857      5.0  \n",
      "204   -0.005143  1.252857      5.0  \n",
      "278    0.024857  0.852857      5.0  \n",
      "282   -0.155143  0.952857      5.0  \n",
      "...         ...       ...      ...  \n",
      "4483  -0.085143  1.902857      5.0  \n",
      "4508   0.114857 -0.047143      5.0  \n",
      "4774   0.034857  0.252857      5.0  \n",
      "5601  -0.205143  1.852857      5.0  \n",
      "5770  -0.045143  1.452857      5.0  \n",
      "\n",
      "[92 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_wine_raw_df[all_wine_raw_df['quality'] == 9].mean() - all_wine_raw_df[all_wine_raw_df['quality'] == 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e1559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
